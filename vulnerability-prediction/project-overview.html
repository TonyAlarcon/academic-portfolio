
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Vulnerability Prediction &#8212; Academic Portfolio</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Source Code Embeddings" href="embeddings.html" />
    <link rel="prev" title="Testing Accuracy" href="../amazon-vision/Testing.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Academic Portfolio</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../particle-accelerator/overview.html">
   Particle Accelerator Simulation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../particle-accelerator/intro.html">
     Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../particle-accelerator/cyclotron.html">
     Cyclotron Code
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../amazon-vision/project-overview.html">
   Amazon Vision Robotics
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../amazon-vision/ClutterizerV2.html">
     Synthetic Image Generator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../amazon-vision/Detectron.html">
     Detectron2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../amazon-vision/Testing.html">
     Testing Accuracy
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Vulnerability Prediction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../wikipedia-image-captioning/report.html">
   Abstract
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../apriori.html">
   Apriori Algorithm
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fvulnerability-prediction/project-overview.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/vulnerability-prediction/project-overview.md"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.md</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Vulnerability Prediction
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#abstract">
   Abstract
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problem-definition">
   Problem Definition
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#source-code-representation-as-ast">
     Source Code Representation as AST
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset-overview">
   Dataset Overview
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning-models">
   Machine Learning Models
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multilayer-perceptron-mlp">
     Multilayer Perceptron (MLP)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolutional-neural-network-cnn">
     Convolutional Neural Network (CNN)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#support-vector-machine-svm">
     Support Vector Machine (SVM)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluation-and-analysis">
   Evaluation and Analysis
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion-and-future-work">
   Conclusion and Future Work
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Vulnerability Prediction</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Vulnerability Prediction
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#abstract">
   Abstract
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#problem-definition">
   Problem Definition
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   Introduction
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#source-code-representation-as-ast">
     Source Code Representation as AST
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#dataset-overview">
   Dataset Overview
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#machine-learning-models">
   Machine Learning Models
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multilayer-perceptron-mlp">
     Multilayer Perceptron (MLP)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convolutional-neural-network-cnn">
     Convolutional Neural Network (CNN)
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#support-vector-machine-svm">
     Support Vector Machine (SVM)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#evaluation-and-analysis">
   Evaluation and Analysis
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#conclusion-and-future-work">
   Conclusion and Future Work
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="vulnerability-prediction">
<h1>Vulnerability Prediction<a class="headerlink" href="#vulnerability-prediction" title="Permalink to this headline">#</a></h1>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="abstract">
<h1>Abstract<a class="headerlink" href="#abstract" title="Permalink to this headline">#</a></h1>
<p>This projec will explore techniques used in the research paper “Vulnerability Prediction From Source Code Using Machine Learning” <span id="id1">[<a class="reference internal" href="#id19" title="Zeki Bilgin, Mehmet Akif Ersoy, Elif Ustundag Soykan, Emrah Tomur, Pinar Çomak, and Leyli Karaçay. Vulnerability prediction from source code using machine learning. IEEE Access, 8():150672-150684, 2020. doi:10.1109/ACCESS.2020.3016774.">BES+20</a>]</span>. Software assurance and automation of software vulnerability detection is a crucial aspect of the security industry. To this end, the project replicates the exact source code embedding techniques utilized by Bilgin et al., and tests the embedding on various machine learning algorithms to perform intelligent analysis on source code in order to correctly predict vulnerabilities. The three machine learning algorithms that we present are a Multi-layer Perceptron (MLP) Model, a Convolutional Neural Network (CNN) Model, and lastly a Support Vector Machine (SVM) model. All three models were able to produce high accuracy, precision, and recall metrics on our curated CWE datasets</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="problem-definition">
<h1>Problem Definition<a class="headerlink" href="#problem-definition" title="Permalink to this headline">#</a></h1>
<p>Software vulnerabilities may have widespread impact; depending on it’s severity, a single vulnerability can compromise an entire system. As such it is in the developers and investor’s best interest to identify possible vulnerabilities early on to mitigate it’s impact while in deployment. Nevertheless, vulnerabilities are often difficult to detect, decipher, and prevent. Dynamic and Static Analysis tools are the standard accepted approaches to detecting vulnerabilities, however, they come with limitations, drawbacks and are far from perfect. For example, static analysis tool tend to analyze a program by exploring all the different paths that the program can take, without executing the code. However, this makes them susceptible to vulnerabilities that can occur during runtime. Additionally, exploring all different paths in a program quickly becomes exponentially expensive, and may be time consuming especially for large applications. Furthermore, static analysis tools can only analyze limited properties of the program. For Dynamic Analysis tools, we analyze a program by executing the code to check how it behaves during runtime, however, we are usually limited to analyzing a single path in a program. As such, vulnerability detection becomes ineffective if all path are not properly covered. It has been shown that static and dynamic analysis tools are ineffective for detecting certain vulnerabilities <span id="id2">[<a class="reference internal" href="#id23">DSB+18</a>]</span>. As such, Bilgin, et. al. proposes an additional approach that leverages state of the art machine learning models for vulnerability detection from source code.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">#</a></h1>
<p>Source code is a collection of code identifiers, written in human-readable alphanumeric characters that serves to bridge the gap between machine and human language. As such, academic researchers have leveraged word embedding techniques to capture the predictable statistical properties in source code for many software engineering tasks <span id="id3">[<a class="reference internal" href="#id24" title="Vasiliki Efstathiou and Diomidis Spinellis. Semantic source code models using identifier embeddings. In Proceedings of the 16th International Conference on Mining Software Repositories, MSR '19, 29–33. IEEE Press, 2019. URL: https://doi.org/10.1109/MSR.2019.00015, doi:10.1109/MSR.2019.00015.">ES19</a>]</span>. Such contemporary word embedding techniques transforms a natural language into contiguous numerical vectors that preserves syntactical and semantical meaning in words/sentences. Nevertheless, the authors in <span id="id4">[<a class="reference internal" href="#id17" title="Jian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, Kaixuan Wang, and Xudong Liu. A novel neural source code representation based on abstract syntax tree. In Proceedings of the 41st International Conference on Software Engineering, ICSE '19, 783–794. IEEE Press, 2019. URL: https://doi.org/10.1109/ICSE.2019.00086, doi:10.1109/ICSE.2019.00086.">ZWZ+19</a>]</span>, <span id="id5">[<a class="reference internal" href="#id18" title="Yaqin Zhou, Shangqing Liu, Jing Kai Siow, Xiaoning Du, and Yang Liu. Devign: effective vulnerability identification by learning comprehensive program semantics via graph neural networks. CoRR, 2019. URL: http://arxiv.org/abs/1909.03496, arXiv:1909.03496.">ZLS+19</a>]</span> have demonstrated that source code can not only be interpreted as a natural languages, but additionally has many representative forms such as AST, data flow, and control flow. Therefore, numerous studies have been performed that aims to find an efficient representation  of source code for ML applications  that captures comprehensive semantics to characterize complex and diverse vulnerabilities. This paper will explore, verify and replicate the techniques employed by Belgin, et. al. <span id="id6">[<a class="reference internal" href="#id19" title="Zeki Bilgin, Mehmet Akif Ersoy, Elif Ustundag Soykan, Emrah Tomur, Pinar Çomak, and Leyli Karaçay. Vulnerability prediction from source code using machine learning. IEEE Access, 8():150672-150684, 2020. doi:10.1109/ACCESS.2020.3016774.">BES+20</a>]</span>
for predicting vulnerabilities from source code using a Machine Learning Approach.</p>
<section id="source-code-representation-as-ast">
<h2>Source Code Representation as AST<a class="headerlink" href="#source-code-representation-as-ast" title="Permalink to this headline">#</a></h2>
<p>Belgin, et. al. employ a seven step approach to develop a meaningful representation of the source code, briefly described below.</p>
<ol class="simple">
<li><p>Source Code. Fragments of source code in a particular high-level programming language are selected such that AST can be obtained using appropriate parsers. Appropriate languages include Python, C++, C, Java, etc.</p></li>
<li><p>Function-Level Partition Source code has various constituents compromising of components, functions, classes, lines, etc. This step extracts function-level code from source code to reduce arbitrarily long lines of code. Function-level source code is chosen given that it captures the overall flow of subroutine and provides a more precise localization for predicting vulnerabilities.</p></li>
<li><p>Tokenization. This step first removes unnecessary elements such as spaces, tabs, comments and commas from function-level code and converts the remaining code identifiers into tokens.</p></li>
<li><p>AST Generation Using appropriate parsers for a given language, AST’s are generated from tokenized source code that contains syntactic and semantic meanings.</p></li>
<li><p>Conversion to Complete Binary AST AST must be converted into a data structure that conforms to the Machine Learning input prerequisites. To that end, AST are first converted into binary trees to preserve the structural relations of nodes.</p></li>
<li><p>Encoding to Numerical Tuples This step simply maps the nodes into predetermined numerical tuples, each with 3 values. The first element represent the type of token, while the second and third element is used to maintain auxiliary information that exists at the node.</p></li>
<li><p>Array Representation Lastly, numeric arrays are generated from the numerical tuples such that they preserve the locations of the nodes in a Tree.</p></li>
</ol>
<p>The rest of this paper is organized as follows. In section 3, we provide an overview of the dataset utilized for training and discuss under-sampling method. In section 4, we provide an in-depth discussion of Belgin’s novel source code embedding methods with examples. Then in section 5, we provide the machine learning algorithms utilized for this paper and it’s corresponding hyper parameters. In section 6, we analyze the results obtained for each training model in the proceeding section. Lastly, section 7 concludes the paper and provides future work considerations.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="dataset-overview">
<h1>Dataset Overview<a class="headerlink" href="#dataset-overview" title="Permalink to this headline">#</a></h1>
<p>This paper utilizes the public Draper VDISC Dataset. This dataset contains 1.27 million function-level C code samples mined from various open source projects, which includes, but is not limited to, Debian Linux Distribution, NIST’s Samate, SATE IV Juilet Test Suite and many other public repositories on Github. For more information about this dataset, please refer to <span id="id7">[<a class="reference internal" href="#id20" title="Rebecca L. Russell, Louis Y. Kim, Lei H. Hamilton, Tomo Lazovich, Jacob A. Harer, Onur Ozdemir, Paul M. Ellingwood, and Marc W. McConley. Automated vulnerability detection in source code using deep representation learning. CoRR, 2018. URL: http://arxiv.org/abs/1807.04320, arXiv:1807.04320.">RKH+18</a>]</span>.</p>
<p>While this dataset contains extensive training data, roughly 91.35% of the samples could not be compiled (and thus unusable for our purposes) for various reasons, i.e. missing semicolon ‘;’ at the end of statements, syntax errors, etc. As such, this paper focuses on the 122,601 compilable function-level source code. As shown in Fig. ~\ref{fig:label_distribution}, the label distribution for the sampled dataset is highly imbalanced, with vulnerable functions corresponding to less than 10% of the available data. This skewed class distribution may lead to unequal miss-classification costs during the training process, as such the machine learning models are ill-equipped to learn meaningful characteristic that are indicative of vulnerable functions. Therefore this issue must be addressed in order to avoid poor predictability performance on the minority class. This paper utilizes the under-sampling technique, in which all vulnerable functions are kept and non-vulnerable functions are randomly sampled without replacement until the size of the labels in the training set are equal. All machine learning models discussed in subsequent sections are then trained on this under-sampled balanced dataset.</p>
<figure class="align-default">
<img alt="../_images/label_dis.png" src="../_images/label_dis.png" />
</figure>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="machine-learning-models">
<h1>Machine Learning Models<a class="headerlink" href="#machine-learning-models" title="Permalink to this headline">#</a></h1>
<p>After adequate source code representation has been generated, this paper leverages state of the art machine learning algorithms and present a comparative analysis on its performance. The algorithms presented will extend beyond the algorithms presented in <span id="id8">[<a class="reference internal" href="#id19" title="Zeki Bilgin, Mehmet Akif Ersoy, Elif Ustundag Soykan, Emrah Tomur, Pinar Çomak, and Leyli Karaçay. Vulnerability prediction from source code using machine learning. IEEE Access, 8():150672-150684, 2020. doi:10.1109/ACCESS.2020.3016774.">BES+20</a>]</span>. This subsection provides a quick discussion of the machine leaning models utilized and it’s hyperparameters.</p>
<section id="multilayer-perceptron-mlp">
<h2>Multilayer Perceptron (MLP)<a class="headerlink" href="#multilayer-perceptron-mlp" title="Permalink to this headline">#</a></h2>
<p>Multilayer perceptrons are a class of fully connected layers of neurons, typically subdivided into input, hidden, and output layers. Each neuron in the MLP computes a weighted sum of it’s input and uses a non-linear activation function to transform it’s input. Such operations performed successively layer by layer has been proven to make the MLP model an universal appropriator, also referred to as the Universal Approximation Theorem <span id="id9">[<a class="reference internal" href="#id21" title="Kurt Hornik, Maxwell B. Stinchcombe, and Halbert L. White. Multilayer feedforward networks are universal approximators. Neural Networks, 2:359-366, 1989.">HSW89</a>]</span>. MLP models have a high degree of customizability, and often vary in number and size of their hidden layers, which may have different effects in different types of training data. This paper utilizes the hyperparameters displayed in Table [] to construct a binary classifier on the under-sampled balanced dataset.</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>Hyper-parameter</p></th>
<th class="text-align:right head"><p>Value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>Optimizer</p></td>
<td class="text-align:right"><p>Adam</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Hidden Nodes</p></td>
<td class="text-align:right"><p>10</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Batch Size</p></td>
<td class="text-align:right"><p>250</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Activation</p></td>
<td class="text-align:right"><p>ReLU</p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Loss Function</p></td>
<td class="text-align:right"><p>Binary Cross Entropy</p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Epochs</p></td>
<td class="text-align:right"><p>40</p></td>
</tr>
</tbody>
</table>
</section>
<section id="convolutional-neural-network-cnn">
<h2>Convolutional Neural Network (CNN)<a class="headerlink" href="#convolutional-neural-network-cnn" title="Permalink to this headline">#</a></h2>
<p>Convolutional Neural Networks are another archetype of artificial neural networks known for their weight-sharing mechanism which may learn to become invariant to translation and rotation <span id="id10">[<a class="reference internal" href="#id22">BB21</a>]</span>. CNNs may contain several successive layers of convolution and pooling as a pre-processing step prior to a fully connected multi-layer perception. The convolution layer uses various filters/kernals of fixed sized that performs a convolution operation across the entire image creating a distinct feature maps for each kernel. The pooling layer typically operates on the feature map to further sample the output via averaging or max sampling across a fixed region. The CNN’s hyper-parameters utilized for this paper are described in Table</p>
</section>
<section id="support-vector-machine-svm">
<h2>Support Vector Machine (SVM)<a class="headerlink" href="#support-vector-machine-svm" title="Permalink to this headline">#</a></h2>
<p>Support Vector Machines are robust machine learning models for classification problems. SVMs map data to a higher dimensional feature space, in order to separate data into classes. This works by first fitting the data with a graphical separator, then attempting to maximize the distance between each class to to the hyperplane boundary. The only hyperparameter used to train the SVM was the decision function shape, “OVO”, meaning a one v. one approach for multi-class classification where the number of generated models is proportional to the number of classes. This is the standard approach for SVM design using the sklearn library.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="evaluation-and-analysis">
<h1>Evaluation and Analysis<a class="headerlink" href="#evaluation-and-analysis" title="Permalink to this headline">#</a></h1>
<p>To properly quantify the results of the machine learning models on the 5 training sets, we display precision-recall curves that show the trade-off between precision and recall for different thresholds below. A higher area under the curve represents both high recall and high precision, where high precision corresponds to a low false positive rate, and high recall corresponds to a low false negative rate. High scores for both show that the classifier is returning accurate results (better precision), as well as returning a majority of all positive results (better recall). The goal is to have a large area under the curve for all data sets.</p>
<p>Beginning with the MLP model, we see that the model performed best on CWE-IDs 119 and 120. This is because the model is able to generalize relatively well on a more evenly distributed dataset, whereas the model struggled consequently on CWE-Other, indicative of multiple vulnerabilities lumped into one category. The MLP model was the third best model with its highest accuracy of 88% on CWE-119. Next, the CNN model performed exceedingly well for all CWE-IDs except CWE-469. This is because DNN (Deep Neural Networks) require significant training samples to properly generalize, and the CNN was not able to perform well with a low sampled dataset (around 100 samples), such as CWE-469. However, the CNN performed the second best with a high accuracy score of 93% on CWE-other, and proportionally high precision and recall metrics. Lastly, the SVM model outperformed all other models in accuracy, precision, and recall with the highest score being 95% in all three metrics. The ROC curve looks very straight, because the precision and recall scores were so evenly balanced for each dataset. SVM models are simple, but paradigm models for classification problems. In this situation, it was able to classify well with a simple classification problem and highly embedded/processed data. We hypothesize that this is due to SVMs consistent performance with two-class problems (binary classifications), and datasets free of noise.</p>
<figure class="align-default">
<img alt="../_images/CNN_ROC.png" src="../_images/CNN_ROC.png" />
</figure>
<figure class="align-default">
<img alt="../_images/MLP_ROC.png" src="../_images/MLP_ROC.png" />
</figure>
<figure class="align-default">
<img alt="../_images/ROC.png" src="../_images/ROC.png" />
</figure>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="conclusion-and-future-work">
<h1>Conclusion and Future Work<a class="headerlink" href="#conclusion-and-future-work" title="Permalink to this headline">#</a></h1>
<p>In conclusion, this article has demonstrated that Bilgin’s novel source code embedding methods works well in the context of vulnerability prediction. All three of our machine learning algorithms were able to generate high accuracy, precision, and recall scores with regards to properly classifying data to its CWE-ID. For future work in this project, we would like to explore other alternatives to Belgin’s source code embedding method, including BERT (an NLP technique derived by Google), and Code2Vec (an alternative state of the art embedding technique).</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="references">
<h1>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h1>
<div class="docutils container" id="id11">
<dl class="citation">
<dt class="label" id="id19"><span class="brackets">BES+20</span><span class="fn-backref">(<a href="#id1">1</a>,<a href="#id6">2</a>,<a href="#id8">3</a>)</span></dt>
<dd><p>Zeki Bilgin, Mehmet Akif Ersoy, Elif Ustundag Soykan, Emrah Tomur, Pinar Çomak, and Leyli Karaçay. Vulnerability prediction from source code using machine learning. <em>IEEE Access</em>, 8():150672–150684, 2020. <a class="reference external" href="https://doi.org/10.1109/ACCESS.2020.3016774">doi:10.1109/ACCESS.2020.3016774</a>.</p>
</dd>
<dt class="label" id="id22"><span class="brackets"><a class="fn-backref" href="#id10">BB21</a></span></dt>
<dd><p><strong>missing journal in https://doi.org/10.48550/arxiv.2110.05861</strong></p>
</dd>
<dt class="label" id="id23"><span class="brackets"><a class="fn-backref" href="#id2">DSB+18</a></span></dt>
<dd><p><strong>missing booktitle in Delaitre2018SATEVR</strong></p>
</dd>
<dt class="label" id="id24"><span class="brackets"><a class="fn-backref" href="#id3">ES19</a></span></dt>
<dd><p>Vasiliki Efstathiou and Diomidis Spinellis. Semantic source code models using identifier embeddings. In <em>Proceedings of the 16th International Conference on Mining Software Repositories</em>, MSR '19, 29–33. IEEE Press, 2019. URL: <a class="reference external" href="https://doi.org/10.1109/MSR.2019.00015">https://doi.org/10.1109/MSR.2019.00015</a>, <a class="reference external" href="https://doi.org/10.1109/MSR.2019.00015">doi:10.1109/MSR.2019.00015</a>.</p>
</dd>
<dt class="label" id="id21"><span class="brackets"><a class="fn-backref" href="#id9">HSW89</a></span></dt>
<dd><p>Kurt Hornik, Maxwell B. Stinchcombe, and Halbert L. White. Multilayer feedforward networks are universal approximators. <em>Neural Networks</em>, 2:359–366, 1989.</p>
</dd>
<dt class="label" id="id20"><span class="brackets"><a class="fn-backref" href="#id7">RKH+18</a></span></dt>
<dd><p>Rebecca L. Russell, Louis Y. Kim, Lei H. Hamilton, Tomo Lazovich, Jacob A. Harer, Onur Ozdemir, Paul M. Ellingwood, and Marc W. McConley. Automated vulnerability detection in source code using deep representation learning. <em>CoRR</em>, 2018. URL: <a class="reference external" href="http://arxiv.org/abs/1807.04320">http://arxiv.org/abs/1807.04320</a>, <a class="reference external" href="https://arxiv.org/abs/1807.04320">arXiv:1807.04320</a>.</p>
</dd>
<dt class="label" id="id17"><span class="brackets"><a class="fn-backref" href="#id4">ZWZ+19</a></span></dt>
<dd><p>Jian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, Kaixuan Wang, and Xudong Liu. A novel neural source code representation based on abstract syntax tree. In <em>Proceedings of the 41st International Conference on Software Engineering</em>, ICSE '19, 783–794. IEEE Press, 2019. URL: <a class="reference external" href="https://doi.org/10.1109/ICSE.2019.00086">https://doi.org/10.1109/ICSE.2019.00086</a>, <a class="reference external" href="https://doi.org/10.1109/ICSE.2019.00086">doi:10.1109/ICSE.2019.00086</a>.</p>
</dd>
<dt class="label" id="id18"><span class="brackets"><a class="fn-backref" href="#id5">ZLS+19</a></span></dt>
<dd><p>Yaqin Zhou, Shangqing Liu, Jing Kai Siow, Xiaoning Du, and Yang Liu. Devign: effective vulnerability identification by learning comprehensive program semantics via graph neural networks. <em>CoRR</em>, 2019. URL: <a class="reference external" href="http://arxiv.org/abs/1909.03496">http://arxiv.org/abs/1909.03496</a>, <a class="reference external" href="https://arxiv.org/abs/1909.03496">arXiv:1909.03496</a>.</p>
</dd>
</dl>
</div>
<div class="toctree-wrapper compound">
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./vulnerability-prediction"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../amazon-vision/Testing.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Testing Accuracy</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="embeddings.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Source Code Embeddings</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Tony Alarcon<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>