
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Detectron2 &#8212; Academic Portfolio</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=62ba249389abaaa9ffc34bf36a076bdc1d65ee18" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=f31d14ad54b65d19161ba51d4ffff3a77ae00456"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Importing Trained Model" href="Testing.html" />
    <link rel="prev" title="Synthetic Image Generator" href="ClutterizerV2.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Academic Portfolio</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../markdown.html">
   Markdown Files
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../notebooks.html">
   Content with notebooks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../markdown-notebooks.html">
   Notebooks with MyST Markdown
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../particle-accelerator/overview.html">
   Particle Accelerator Simulation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../particle-accelerator/intro.html">
     Introduction
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../particle-accelerator/cyclotron.html">
     Cyclotron Code
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../vulnerability-prediction/project-overview.html">
   Vulnerability Prediction
  </a>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="project-overview.html">
   Amazon Vision Robotics
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="ClutterizerV2.html">
     Synthetic Image Generator
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Detectron2
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="Testing.html">
     Importing Trained Model
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../apriori.html">
   Apriori Algorithm
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/amazon-vision/Detectron.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Famazon-vision/Detectron.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../_sources/amazon-vision/Detectron.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Detectron2
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fine-tunning-and-training">
   Fine Tunning and Training
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-curves">
   Training Curves
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Detectron2</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Detectron2
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fine-tunning-and-training">
   Fine Tunning and Training
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#training-curves">
   Training Curves
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="detectron2">
<h1>Detectron2<a class="headerlink" href="#detectron2" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="ch">#!pip install pyyaml==5.1</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">TORCH_VERSION</span> <span class="o">=</span> <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[:</span><span class="mi">2</span><span class="p">])</span>
<span class="n">CUDA_VERSION</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;+&quot;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;torch: &quot;</span><span class="p">,</span> <span class="n">TORCH_VERSION</span><span class="p">,</span> <span class="s2">&quot;; cuda: &quot;</span><span class="p">,</span> <span class="n">CUDA_VERSION</span><span class="p">)</span>
<span class="c1"># Install detectron2 that matches the above pytorch version</span>
<span class="c1"># See https://detectron2.readthedocs.io/tutorials/install.html for instructions</span>
<span class="o">!</span>pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/<span class="nv">$CUDA_VERSION</span>/torch<span class="nv">$TORCH_VERSION</span>/index.html
<span class="c1"># If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.</span>

<span class="c1">#exit(0)  # After installation, you may need to &quot;restart runtime&quot; in Colab. This line can also restart runtime</span>
<span class="c1"># Some basic setup:</span>
<span class="c1"># Setup detectron2 logger</span>
<span class="kn">import</span> <span class="nn">detectron2</span>
<span class="kn">from</span> <span class="nn">detectron2.utils.logger</span> <span class="kn">import</span> <span class="n">setup_logger</span>
<span class="n">setup_logger</span><span class="p">()</span>

<span class="c1"># import some common libraries</span>
<span class="o">!</span>pip install opencv-python
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">json</span><span class="o">,</span> <span class="nn">cv2</span><span class="o">,</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">google.colab.patches</span> <span class="kn">import</span> <span class="n">cv2_imshow</span>

<span class="c1"># import some common detectron2 utilities</span>
<span class="kn">from</span> <span class="nn">detectron2</span> <span class="kn">import</span> <span class="n">model_zoo</span>
<span class="kn">from</span> <span class="nn">detectron2.engine</span> <span class="kn">import</span> <span class="n">DefaultPredictor</span>
<span class="kn">from</span> <span class="nn">detectron2.config</span> <span class="kn">import</span> <span class="n">get_cfg</span>
<span class="kn">from</span> <span class="nn">detectron2.utils.visualizer</span> <span class="kn">import</span> <span class="n">Visualizer</span>
<span class="kn">from</span> <span class="nn">detectron2.data</span> <span class="kn">import</span> <span class="n">MetadataCatalog</span><span class="p">,</span> <span class="n">DatasetCatalog</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch:  1.10 ; cuda:  cu111
Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html
Requirement already satisfied: detectron2 in /usr/local/lib/python3.7/dist-packages (0.6+cu111)
Requirement already satisfied: tqdm&gt;4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.64.0)
Requirement already satisfied: yacs&gt;=0.1.8 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.8)
Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)
Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)
Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.8.0)
Requirement already satisfied: hydra-core&gt;=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.2)
Requirement already satisfied: iopath&lt;0.1.10,&gt;=0.1.7 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.9)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)
Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)
Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)
Requirement already satisfied: fvcore&lt;0.1.6,&gt;=0.1.5 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.5.post20220414)
Requirement already satisfied: termcolor&gt;=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)
Requirement already satisfied: pycocotools&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.4)
Requirement already satisfied: black==21.4b2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (21.4b2)
Requirement already satisfied: Pillow&gt;=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)
Requirement already satisfied: omegaconf&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.1.2)
Requirement already satisfied: typed-ast&gt;=1.4.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2-&gt;detectron2) (1.5.3)
Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2-&gt;detectron2) (1.4.4)
Requirement already satisfied: click&gt;=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2-&gt;detectron2) (7.1.2)
Requirement already satisfied: typing-extensions&gt;=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2-&gt;detectron2) (4.1.1)
Requirement already satisfied: toml&gt;=0.10.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2-&gt;detectron2) (0.10.2)
Requirement already satisfied: mypy-extensions&gt;=0.4.3 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2-&gt;detectron2) (0.4.3)
Requirement already satisfied: regex&gt;=2020.1.8 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2-&gt;detectron2) (2022.3.15)
Requirement already satisfied: pathspec&lt;1,&gt;=0.8.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2-&gt;detectron2) (0.9.0)
Requirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore&lt;0.1.6,&gt;=0.1.5-&gt;detectron2) (6.0)
Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore&lt;0.1.6,&gt;=0.1.5-&gt;detectron2) (1.21.6)
Requirement already satisfied: importlib-resources&lt;5.3 in /usr/local/lib/python3.7/dist-packages (from hydra-core&gt;=1.1-&gt;detectron2) (5.2.3)
Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core&gt;=1.1-&gt;detectron2) (4.8)
Requirement already satisfied: zipp&gt;=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources&lt;5.3-&gt;hydra-core&gt;=1.1-&gt;detectron2) (3.8.0)
Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath&lt;0.1.10,&gt;=0.1.7-&gt;detectron2) (2.4.0)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;detectron2) (3.0.8)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;detectron2) (2.8.2)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;detectron2) (0.11.0)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;detectron2) (1.4.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.1-&gt;matplotlib-&gt;detectron2) (1.15.0)
Requirement already satisfied: werkzeug&gt;=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;detectron2) (1.0.1)
Requirement already satisfied: setuptools&gt;=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;detectron2) (57.4.0)
Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;detectron2) (1.35.0)
Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;detectron2) (0.4.6)
Requirement already satisfied: protobuf&gt;=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;detectron2) (3.17.3)
Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;detectron2) (1.8.1)
Requirement already satisfied: wheel&gt;=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;detectron2) (0.37.1)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;detectron2) (3.3.6)
Requirement already satisfied: grpcio&gt;=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;detectron2) (1.44.0)
Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;detectron2) (0.6.1)
Requirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;detectron2) (1.0.0)
Requirement already satisfied: requests&lt;3,&gt;=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard-&gt;detectron2) (2.23.0)
Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;detectron2) (4.2.4)
Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;detectron2) (4.8)
Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;detectron2) (0.2.8)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;detectron2) (1.3.1)
Requirement already satisfied: importlib-metadata&gt;=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown&gt;=2.6.8-&gt;tensorboard-&gt;detectron2) (4.11.3)
Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard-&gt;detectron2) (0.4.8)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard-&gt;detectron2) (2021.10.8)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard-&gt;detectron2) (2.10)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard-&gt;detectron2) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorboard-&gt;detectron2) (1.24.3)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard-&gt;detectron2) (3.2.0)
Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)
Requirement already satisfied: numpy&gt;=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#uncoment when working on Google Colab</span>
<span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s2">&quot;/content/gdrive&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mounted at /content/gdrive
/content
</pre></div>
</div>
</div>
</div>
<p>I used <a class="reference external" href="https://plainsight.ai">https://plainsight.ai</a> to perform polygon annotations and exported the data utilizing their COCO format feature. However, the images segmentations are exported in the following format “segmentation” : [[x_1, y_1], [x_2, y_2], …] which is not the forma expected from detectron2. Thefore, we first need to flatten the segmentation array of arrays prior to registering with detectron. The cell below takes care of that</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">json</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="k">def</span> <span class="nf">convert_to_COCO</span><span class="p">(</span><span class="n">json_path</span><span class="p">):</span>
  <span class="c1">#variable where we will save our new json object</span>
    <span class="n">new_json</span> <span class="o">=</span> <span class="kc">None</span>
    
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">json_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">json_object</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file</span><span class="p">)</span>
        <span class="n">annotations</span> <span class="o">=</span> <span class="n">json_object</span><span class="p">[</span><span class="s1">&#39;annotations&#39;</span><span class="p">]</span>
    <span class="c1">#function to flatten the array of arrays</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">annotations</span><span class="p">)):</span>
        <span class="n">annotations</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;segmentation&quot;</span><span class="p">]</span>  <span class="o">=</span>  <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">annotations</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="s2">&quot;segmentation&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()]</span>

    <span class="c1">#save to json object </span>
    <span class="n">json_object</span><span class="p">[</span><span class="s1">&#39;annotations&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">annotations</span>

    <span class="n">new_json</span> <span class="o">=</span> <span class="n">json_object</span>
    <span class="k">return</span> <span class="n">new_json</span>


<span class="c1">#function to save a json file to selected path, note we should append the name of the file</span>
<span class="k">def</span> <span class="nf">save_JSON</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>


<span class="c1">#Google colab path</span>
<span class="c1">#dataset_path = &quot;/content/gdrive/MyDrive/Spring 2022 Courses/Neural Networks/Amazon-Robotics-snapshot-001-project-coco-1646593032&quot;</span>
<span class="n">dataset_path</span> <span class="o">=</span> <span class="s1">&#39;/content/gdrive/MyDrive/Amazon Project/clutterized/&#39;</span>
<span class="c1">#scratch365 path</span>
<span class="c1">#dataset_path = &quot;./Amazon-Robotics-snapshot-001-project-coco-1646593032&quot;</span>
<span class="n">old_annotations_train</span> <span class="o">=</span> <span class="n">dataset_path</span> <span class="o">+</span> <span class="s2">&quot;/train.json&quot;</span>
<span class="n">image_path</span> <span class="o">=</span> <span class="n">dataset_path</span> 


<span class="n">new_json_train</span> <span class="o">=</span> <span class="n">convert_to_COCO</span><span class="p">(</span><span class="n">old_annotations_train</span><span class="p">)</span>
<span class="n">save_JSON</span><span class="p">(</span><span class="n">new_json_train</span><span class="p">,</span> <span class="n">dataset_path</span><span class="o">+</span><span class="s2">&quot;new_train.json&quot;</span><span class="p">)</span>
<span class="n">annotations_train</span> <span class="o">=</span> <span class="n">dataset_path</span> <span class="o">+</span> <span class="s2">&quot;new_train.json&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>If we want to use a custom dataset while also reusing detectron2’s data loaders, you will need to:</p>
<ol class="simple">
<li><p>Register your dataset (i.e., tell detectron2 how to obtain your dataset).</p></li>
<li><p>Optionally, register metadata for your dataset.</p></li>
</ol>
<p>It contains a mapping from strings (which are names that identify a dataset, e.g. “coco_2014_train”) to a function which parses the dataset and returns the samples in the format of list[dict].</p>
<p>For more details: <a class="reference external" href="https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html">https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html</a></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">detectron2.data.datasets</span> <span class="kn">import</span> <span class="n">register_coco_instances</span>
<span class="kn">from</span> <span class="nn">detectron2.structures</span> <span class="kn">import</span> <span class="n">BoxMode</span>

<span class="c1">#telling detectron what to call my training dataset, path to json file, and path to images</span>
<span class="n">register_coco_instances</span><span class="p">(</span><span class="s2">&quot;my_dataset_train&quot;</span><span class="p">,</span> <span class="p">{},</span> <span class="n">annotations_train</span><span class="p">,</span> <span class="n">image_path</span><span class="p">)</span>

<span class="c1">#visualize training data</span>
<span class="n">train_metadata</span> <span class="o">=</span> <span class="n">MetadataCatalog</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;my_dataset_train&quot;</span><span class="p">)</span>
<span class="n">train_dataset</span> <span class="o">=</span> <span class="n">DatasetCatalog</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;my_dataset_train&quot;</span><span class="p">)</span> <span class="c1">#Call the registered function and return its results (return list[dict] – dataset annotations.)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[04/24 15:57:57 d2.data.datasets.coco]: </span>Loaded 44 images in COCO format from /content/gdrive/MyDrive/Amazon Project/clutterized/new_train.json
</pre></div>
</div>
</div>
</div>
<p>Here we visualize random sample from our dataset, including the bbox, polygon segmentation and it’s label</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>
<span class="kn">from</span> <span class="nn">detectron2.utils.visualizer</span> <span class="kn">import</span> <span class="n">Visualizer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">rows</span><span class="p">,</span> <span class="n">cols</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">3</span>
<span class="n">j</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">45</span><span class="p">,</span><span class="mi">45</span><span class="p">))</span>

<span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">train_dataset</span><span class="p">,</span> <span class="mi">11</span><span class="p">):</span> <span class="c1">#returns 11 random samples from the training dataset</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">d</span><span class="p">[</span><span class="s2">&quot;file_name&quot;</span><span class="p">])</span> <span class="c1">#respective file name</span>
    <span class="n">visualizer</span> <span class="o">=</span> <span class="n">Visualizer</span><span class="p">(</span><span class="n">img</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">metadata</span><span class="o">=</span><span class="n">train_metadata</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">visualizer</span><span class="o">.</span><span class="n">draw_dataset_dict</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">j</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">j</span> <span class="o">=</span> <span class="n">j</span><span class="o">+</span> <span class="mi">1</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">get_image</span><span class="p">()[:,</span> <span class="p">:,</span> <span class="p">::</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>


<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Output hidden; open in https://colab.research.google.com to view.
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="fine-tunning-and-training">
<h1>Fine Tunning and Training<a class="headerlink" href="#fine-tunning-and-training" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">detectron2.engine</span> <span class="kn">import</span> <span class="n">DefaultTrainer</span>

<span class="n">cfg</span> <span class="o">=</span> <span class="n">get_cfg</span><span class="p">()</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">merge_from_file</span><span class="p">(</span><span class="n">model_zoo</span><span class="o">.</span><span class="n">get_config_file</span><span class="p">(</span><span class="s2">&quot;COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml&quot;</span><span class="p">))</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">DATASETS</span><span class="o">.</span><span class="n">TRAIN</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;my_dataset_train&quot;</span><span class="p">,)</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">DATASETS</span><span class="o">.</span><span class="n">TEST</span> <span class="o">=</span> <span class="p">()</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">DATALOADER</span><span class="o">.</span><span class="n">NUM_WORKERS</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">WEIGHTS</span> <span class="o">=</span> <span class="n">model_zoo</span><span class="o">.</span><span class="n">get_checkpoint_url</span><span class="p">(</span><span class="s2">&quot;COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml&quot;</span><span class="p">)</span>  <span class="c1"># Let training initialize from model zoo</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">SOLVER</span><span class="o">.</span><span class="n">IMS_PER_BATCH</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">SOLVER</span><span class="o">.</span><span class="n">BASE_LR</span> <span class="o">=</span> <span class="mf">0.00025</span>  <span class="c1"># pick a good LR</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">SOLVER</span><span class="o">.</span><span class="n">MAX_ITER</span> <span class="o">=</span> <span class="mi">600</span>  <span class="c1"># 600 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">SOLVER</span><span class="o">.</span><span class="n">STEPS</span> <span class="o">=</span> <span class="p">[]</span>        <span class="c1"># do not decay learning rate</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">ROI_HEADS</span><span class="o">.</span><span class="n">BATCH_SIZE_PER_IMAGE</span> <span class="o">=</span> <span class="mi">200</span>  <span class="c1"># faster, and good enough for this toy dataset (default: 512)</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">MODEL</span><span class="o">.</span><span class="n">ROI_HEADS</span><span class="o">.</span><span class="n">NUM_CLASSES</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)</span>
<span class="c1"># NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.</span>
<span class="n">cfg</span><span class="o">.</span><span class="n">OUTPUT_DIR</span> <span class="o">=</span> <span class="s1">&#39;/content/gdrive/MyDrive/Amazon Project/clutterized/output/&#39;</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">cfg</span><span class="o">.</span><span class="n">OUTPUT_DIR</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1">#trainer = CustomTrainer(cfg)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">DefaultTrainer</span><span class="p">(</span><span class="n">cfg</span><span class="p">)</span> 
<span class="n">trainer</span><span class="o">.</span><span class="n">resume_or_load</span><span class="p">(</span><span class="n">resume</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[04/24 15:58:29 d2.engine.defaults]: </span>Model:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=11, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
<span class=" -Color -Color-Green">[04/24 15:58:29 d2.data.datasets.coco]: </span>Loaded 44 images in COCO format from /content/gdrive/MyDrive/Amazon Project/clutterized/new_train.json
<span class=" -Color -Color-Green">[04/24 15:58:29 d2.data.build]: </span>Removed 0 images with no usable annotations. 44 images left.
<span class=" -Color -Color-Green">[04/24 15:58:29 d2.data.build]: </span>Distribution of instances among all 10 categories:
<span class=" -Color -Color-Cyan">|  category  | #instances   |  category  | #instances   |  category  | #instances   |</span>
<span class=" -Color -Color-Cyan">|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|</span>
<span class=" -Color -Color-Cyan">|    ball    | 26           | calculator | 43           | controller | 43           |</span>
<span class=" -Color -Color-Cyan">|    cup     | 38           | hair brush | 41           | hard drive | 29           |</span>
<span class=" -Color -Color-Cyan">|  head set  | 46           |  keyboard  | 50           |   mouse    | 41           |</span>
<span class=" -Color -Color-Cyan">|   tongs    | 35           |            |              |            |              |</span>
<span class=" -Color -Color-Cyan">|   total    | 392          |            |              |            |              |</span>
<span class=" -Color -Color-Green">[04/24 15:58:29 d2.data.dataset_mapper]: </span>[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style=&#39;choice&#39;), RandomFlip()]
<span class=" -Color -Color-Green">[04/24 15:58:29 d2.data.build]: </span>Using training sampler TrainingSampler
<span class=" -Color -Color-Green">[04/24 15:58:29 d2.data.common]: </span>Serializing 44 elements to byte tensors and concatenating them all ...
<span class=" -Color -Color-Green">[04/24 15:58:29 d2.data.common]: </span>Serialized dataset takes 2.99 MiB
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>model_final_f10217.pkl: 178MB [00:04, 39.0MB/s]                           
Skip loading parameter &#39;roi_heads.box_predictor.cls_score.weight&#39; to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter &#39;roi_heads.box_predictor.cls_score.bias&#39; to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.
Skip loading parameter &#39;roi_heads.box_predictor.bbox_pred.weight&#39; to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.
Skip loading parameter &#39;roi_heads.box_predictor.bbox_pred.bias&#39; to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.
Skip loading parameter &#39;roi_heads.mask_head.predictor.weight&#39; to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (10, 256, 1, 1) in the model! You might want to double check if this is expected.
Skip loading parameter &#39;roi_heads.mask_head.predictor.bias&#39; to the model due to incompatible shapes: (80,) in the checkpoint but (10,) in the model! You might want to double check if this is expected.
Some model parameters or buffers are not found in the checkpoint:
<span class=" -Color -Color-Blue">roi_heads.box_predictor.bbox_pred.{bias, weight}</span>
<span class=" -Color -Color-Blue">roi_heads.box_predictor.cls_score.{bias, weight}</span>
<span class=" -Color -Color-Blue">roi_heads.mask_head.predictor.{bias, weight}</span>
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[04/24 15:58:39 d2.engine.train_loop]: </span>Starting training from iteration 0
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the &#39;trunc&#39; function NOT &#39;floor&#39;). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode=&#39;trunc&#39;), or for actual floor division, use torch.div(a, b, rounding_mode=&#39;floor&#39;).
  max_size = (max_size + (stride - 1)) // stride * stride
/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span><span class=" -Color -Color-Green">[04/24 15:59:01 d2.utils.events]: </span> eta: 0:10:31  iter: 19  total_loss: 4.331  loss_cls: 2.549  loss_box_reg: 0.9227  loss_mask: 0.6927  loss_rpn_cls: 0.1782  loss_rpn_loc: 0.05393  time: 1.0924  data_time: 0.5459  lr: 8.1588e-06  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 15:59:20 d2.utils.events]: </span> eta: 0:09:15  iter: 39  total_loss: 4.085  loss_cls: 2.333  loss_box_reg: 0.9114  loss_mask: 0.6892  loss_rpn_cls: 0.121  loss_rpn_loc: 0.04516  time: 1.0082  data_time: 0.3655  lr: 1.6484e-05  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 15:59:38 d2.utils.events]: </span> eta: 0:08:42  iter: 59  total_loss: 3.746  loss_cls: 1.903  loss_box_reg: 0.9199  loss_mask: 0.6836  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.04829  time: 0.9688  data_time: 0.3371  lr: 2.4809e-05  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 15:59:56 d2.utils.events]: </span> eta: 0:08:10  iter: 79  total_loss: 3.102  loss_cls: 1.404  loss_box_reg: 0.9273  loss_mask: 0.6739  loss_rpn_cls: 0.0694  loss_rpn_loc: 0.04122  time: 0.9475  data_time: 0.3284  lr: 3.3134e-05  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:00:14 d2.utils.events]: </span> eta: 0:07:48  iter: 99  total_loss: 2.793  loss_cls: 1.072  loss_box_reg: 0.9228  loss_mask: 0.6563  loss_rpn_cls: 0.03796  loss_rpn_loc: 0.04291  time: 0.9373  data_time: 0.3325  lr: 4.1459e-05  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:00:31 d2.utils.events]: </span> eta: 0:07:25  iter: 119  total_loss: 2.73  loss_cls: 0.9843  loss_box_reg: 0.9369  loss_mask: 0.6406  loss_rpn_cls: 0.08222  loss_rpn_loc: 0.05008  time: 0.9275  data_time: 0.3218  lr: 4.9784e-05  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:00:49 d2.utils.events]: </span> eta: 0:07:04  iter: 139  total_loss: 2.574  loss_cls: 0.9561  loss_box_reg: 0.94  loss_mask: 0.6182  loss_rpn_cls: 0.02298  loss_rpn_loc: 0.04505  time: 0.9228  data_time: 0.3309  lr: 5.8109e-05  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:01:07 d2.utils.events]: </span> eta: 0:06:42  iter: 159  total_loss: 2.511  loss_cls: 0.9129  loss_box_reg: 0.9424  loss_mask: 0.5909  loss_rpn_cls: 0.01956  loss_rpn_loc: 0.03853  time: 0.9174  data_time: 0.3188  lr: 6.6434e-05  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:01:25 d2.utils.events]: </span> eta: 0:06:20  iter: 179  total_loss: 2.491  loss_cls: 0.8972  loss_box_reg: 0.9297  loss_mask: 0.5646  loss_rpn_cls: 0.02218  loss_rpn_loc: 0.04665  time: 0.9135  data_time: 0.2982  lr: 7.4759e-05  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:01:42 d2.utils.events]: </span> eta: 0:06:00  iter: 199  total_loss: 2.392  loss_cls: 0.8662  loss_box_reg: 0.9333  loss_mask: 0.5273  loss_rpn_cls: 0.02129  loss_rpn_loc: 0.04748  time: 0.9110  data_time: 0.3284  lr: 8.3084e-05  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:02:00 d2.utils.events]: </span> eta: 0:05:40  iter: 219  total_loss: 2.327  loss_cls: 0.8342  loss_box_reg: 0.9248  loss_mask: 0.4972  loss_rpn_cls: 0.01584  loss_rpn_loc: 0.04348  time: 0.9074  data_time: 0.3031  lr: 9.1409e-05  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:02:17 d2.utils.events]: </span> eta: 0:05:22  iter: 239  total_loss: 2.274  loss_cls: 0.8155  loss_box_reg: 0.9123  loss_mask: 0.47  loss_rpn_cls: 0.0169  loss_rpn_loc: 0.04992  time: 0.9049  data_time: 0.2962  lr: 9.9734e-05  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:02:35 d2.utils.events]: </span> eta: 0:05:04  iter: 259  total_loss: 2.161  loss_cls: 0.7805  loss_box_reg: 0.9027  loss_mask: 0.4316  loss_rpn_cls: 0.0134  loss_rpn_loc: 0.03518  time: 0.9041  data_time: 0.3199  lr: 0.00010806  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:02:53 d2.utils.events]: </span> eta: 0:04:46  iter: 279  total_loss: 2.137  loss_cls: 0.759  loss_box_reg: 0.8789  loss_mask: 0.4046  loss_rpn_cls: 0.01649  loss_rpn_loc: 0.04464  time: 0.9030  data_time: 0.3081  lr: 0.00011638  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:03:11 d2.utils.events]: </span> eta: 0:04:29  iter: 299  total_loss: 2.069  loss_cls: 0.7347  loss_box_reg: 0.8779  loss_mask: 0.3932  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.04338  time: 0.9022  data_time: 0.3282  lr: 0.00012471  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:03:29 d2.utils.events]: </span> eta: 0:04:10  iter: 319  total_loss: 1.972  loss_cls: 0.6908  loss_box_reg: 0.869  loss_mask: 0.3523  loss_rpn_cls: 0.007592  loss_rpn_loc: 0.03273  time: 0.9022  data_time: 0.3272  lr: 0.00013303  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:03:47 d2.utils.events]: </span> eta: 0:03:53  iter: 339  total_loss: 1.869  loss_cls: 0.6506  loss_box_reg: 0.8385  loss_mask: 0.3205  loss_rpn_cls: 0.01184  loss_rpn_loc: 0.03974  time: 0.9016  data_time: 0.3000  lr: 0.00014136  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:04:05 d2.utils.events]: </span> eta: 0:03:35  iter: 359  total_loss: 1.803  loss_cls: 0.626  loss_box_reg: 0.8169  loss_mask: 0.2917  loss_rpn_cls: 0.01465  loss_rpn_loc: 0.03623  time: 0.9007  data_time: 0.3028  lr: 0.00014968  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:04:23 d2.utils.events]: </span> eta: 0:03:16  iter: 379  total_loss: 1.67  loss_cls: 0.5509  loss_box_reg: 0.7717  loss_mask: 0.2774  loss_rpn_cls: 0.01086  loss_rpn_loc: 0.04062  time: 0.9002  data_time: 0.3069  lr: 0.00015801  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:04:40 d2.utils.events]: </span> eta: 0:02:58  iter: 399  total_loss: 1.485  loss_cls: 0.5029  loss_box_reg: 0.7032  loss_mask: 0.2373  loss_rpn_cls: 0.01232  loss_rpn_loc: 0.03422  time: 0.9000  data_time: 0.3163  lr: 0.00016633  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:04:58 d2.utils.events]: </span> eta: 0:02:40  iter: 419  total_loss: 1.399  loss_cls: 0.4644  loss_box_reg: 0.6432  loss_mask: 0.229  loss_rpn_cls: 0.006946  loss_rpn_loc: 0.04831  time: 0.8989  data_time: 0.3026  lr: 0.00017466  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:05:15 d2.utils.events]: </span> eta: 0:02:22  iter: 439  total_loss: 1.222  loss_cls: 0.3946  loss_box_reg: 0.5513  loss_mask: 0.2265  loss_rpn_cls: 0.004913  loss_rpn_loc: 0.03785  time: 0.8973  data_time: 0.3056  lr: 0.00018298  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:05:33 d2.utils.events]: </span> eta: 0:02:04  iter: 459  total_loss: 1.098  loss_cls: 0.3657  loss_box_reg: 0.477  loss_mask: 0.2051  loss_rpn_cls: 0.00736  loss_rpn_loc: 0.04487  time: 0.8959  data_time: 0.3000  lr: 0.00019131  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:05:50 d2.utils.events]: </span> eta: 0:01:46  iter: 479  total_loss: 1.067  loss_cls: 0.363  loss_box_reg: 0.4549  loss_mask: 0.2125  loss_rpn_cls: 0.004471  loss_rpn_loc: 0.04253  time: 0.8952  data_time: 0.3099  lr: 0.00019963  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:06:08 d2.utils.events]: </span> eta: 0:01:29  iter: 499  total_loss: 0.9235  loss_cls: 0.3044  loss_box_reg: 0.3836  loss_mask: 0.1917  loss_rpn_cls: 0.003291  loss_rpn_loc: 0.03343  time: 0.8940  data_time: 0.2846  lr: 0.00020796  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:06:25 d2.utils.events]: </span> eta: 0:01:11  iter: 519  total_loss: 0.8794  loss_cls: 0.2957  loss_box_reg: 0.3684  loss_mask: 0.1837  loss_rpn_cls: 0.006018  loss_rpn_loc: 0.04379  time: 0.8933  data_time: 0.3159  lr: 0.00021628  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:06:43 d2.utils.events]: </span> eta: 0:00:53  iter: 539  total_loss: 0.8941  loss_cls: 0.2747  loss_box_reg: 0.3733  loss_mask: 0.1874  loss_rpn_cls: 0.003623  loss_rpn_loc: 0.03563  time: 0.8927  data_time: 0.3123  lr: 0.00022461  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:07:00 d2.utils.events]: </span> eta: 0:00:35  iter: 559  total_loss: 0.8498  loss_cls: 0.2725  loss_box_reg: 0.3407  loss_mask: 0.1647  loss_rpn_cls: 0.005101  loss_rpn_loc: 0.04319  time: 0.8924  data_time: 0.3170  lr: 0.00023293  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:07:18 d2.utils.events]: </span> eta: 0:00:17  iter: 579  total_loss: 0.7781  loss_cls: 0.231  loss_box_reg: 0.3311  loss_mask: 0.1745  loss_rpn_cls: 0.004668  loss_rpn_loc: 0.03881  time: 0.8912  data_time: 0.3104  lr: 0.00024126  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:07:38 d2.utils.events]: </span> eta: 0:00:00  iter: 599  total_loss: 0.7412  loss_cls: 0.2268  loss_box_reg: 0.2973  loss_mask: 0.1642  loss_rpn_cls: 0.002852  loss_rpn_loc: 0.03539  time: 0.8913  data_time: 0.3199  lr: 0.00024958  max_mem: 2549M
<span class=" -Color -Color-Green">[04/24 16:07:38 d2.engine.hooks]: </span>Overall training speed: 598 iterations in 0:08:53 (0.8913 s / it)
<span class=" -Color -Color-Green">[04/24 16:07:38 d2.engine.hooks]: </span>Total training time: 0:08:56 (0:00:03 on hooks)
</pre></div>
</div>
</div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="training-curves">
<h1>Training Curves<a class="headerlink" href="#training-curves" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Look at training curves in tensorboard:</span>
<span class="c1">#%load_ext tensorboard</span>
<span class="c1">#%tensorboard --logdir output</span>
</pre></div>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./amazon-vision"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="ClutterizerV2.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Synthetic Image Generator</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Testing.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Importing Trained Model</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Tony Alarcon<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>