{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Detectron2"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11794,"status":"ok","timestamp":1650815857967,"user":{"displayName":"Pedro Alarcon Granadeno","userId":"03221847207112830166"},"user_tz":240},"id":"0mR3LcsMFHYb","outputId":"4b67779c-4256-49f6-dade-fe6692048bee"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch:  1.10 ; cuda:  cu111\n","Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu111/torch1.10/index.html\n","Requirement already satisfied: detectron2 in /usr/local/lib/python3.7/dist-packages (0.6+cu111)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2) (4.64.0)\n","Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.8)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.16.0)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.8.0)\n","Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.2)\n","Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.9)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2) (3.2.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.8.9)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.3.0)\n","Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from detectron2) (0.1.5.post20220414)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (1.1.0)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.0.4)\n","Requirement already satisfied: black==21.4b2 in /usr/local/lib/python3.7/dist-packages (from detectron2) (21.4b2)\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (7.1.2)\n","Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.7/dist-packages (from detectron2) (2.1.2)\n","Requirement already satisfied: typed-ast>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.5.3)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (1.4.4)\n","Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (7.1.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (4.1.1)\n","Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.10.2)\n","Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.4.3)\n","Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (2022.3.15)\n","Requirement already satisfied: pathspec<1,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2) (0.9.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (6.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2) (1.21.6)\n","Requirement already satisfied: importlib-resources<5.3 in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (5.2.3)\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2) (4.8)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources<5.3->hydra-core>=1.1->detectron2) (3.8.0)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2) (2.4.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (3.0.8)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2) (1.4.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2) (1.15.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (57.4.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.35.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.4.6)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.17.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.8.1)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.37.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (3.3.6)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.44.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (0.6.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (1.0.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2) (2.23.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2) (4.11.3)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2) (3.2.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n"]}],"source":["#!pip install pyyaml==5.1\n","\n","import torch\n","TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n","CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n","print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n","# Install detectron2 that matches the above pytorch version\n","# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n","!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n","# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n","\n","#exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime\n","# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","!pip install opencv-python\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15196,"status":"ok","timestamp":1650815873159,"user":{"displayName":"Pedro Alarcon Granadeno","userId":"03221847207112830166"},"user_tz":240},"id":"OuG9k1RcGjFS","outputId":"7d19b786-9078-44ed-ced0-2c75a3157de5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n","/content\n"]}],"source":["#uncoment when working on Google Colab\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","print(os.getcwd())"]},{"cell_type":"markdown","metadata":{"id":"d9bQHh2njRK9"},"source":["I used https://plainsight.ai to perform polygon annotations and exported the data utilizing their COCO format feature. However, the images segmentations are exported in the following format \"segmentation\" : [[x_1, y_1], [x_2, y_2], ...] which is not the forma expected from detectron2. Thefore, we first need to flatten the segmentation array of arrays prior to registering with detectron. The cell below takes care of that"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4093,"status":"ok","timestamp":1650815877241,"user":{"displayName":"Pedro Alarcon Granadeno","userId":"03221847207112830166"},"user_tz":240},"id":"eXcaWEKvKVTW"},"outputs":[],"source":["import json\n","import numpy as np\n","\n","\n","def convert_to_COCO(json_path):\n","  #variable where we will save our new json object\n","    new_json = None\n","    \n","    with open(json_path, 'r') as file:\n","        json_object = json.load(file)\n","        annotations = json_object['annotations']\n","    #function to flatten the array of arrays\n","    for i in range(0, len(annotations)):\n","        annotations[i][\"segmentation\"]  =  [np.array(annotations[i][\"segmentation\"]).flatten().tolist()]\n","\n","    #save to json object \n","    json_object['annotations'] = annotations\n","\n","    new_json = json_object\n","    return new_json\n","\n","\n","#function to save a json file to selected path, note we should append the name of the file\n","def save_JSON(data, path):\n","    with open(path, 'w') as f:\n","        json.dump(data, f, indent=4)\n","\n","\n","#Google colab path\n","#dataset_path = \"/content/gdrive/MyDrive/Spring 2022 Courses/Neural Networks/Amazon-Robotics-snapshot-001-project-coco-1646593032\"\n","dataset_path = '/content/gdrive/MyDrive/Amazon Project/clutterized/'\n","#scratch365 path\n","#dataset_path = \"./Amazon-Robotics-snapshot-001-project-coco-1646593032\"\n","old_annotations_train = dataset_path + \"/train.json\"\n","image_path = dataset_path \n","\n","\n","new_json_train = convert_to_COCO(old_annotations_train)\n","save_JSON(new_json_train, dataset_path+\"new_train.json\")\n","annotations_train = dataset_path + \"new_train.json\"\n","\n"]},{"cell_type":"markdown","metadata":{"id":"UrUIV86bqrcg"},"source":["If we want to use a custom dataset while also reusing detectron2’s data loaders, you will need to:\n","\n","1.   Register your dataset (i.e., tell detectron2 how to obtain your dataset).\n","2.   Optionally, register metadata for your dataset.\n","\n","It contains a mapping from strings (which are names that identify a dataset, e.g. “coco_2014_train”) to a function which parses the dataset and returns the samples in the format of list[dict]. \n","\n","For more details: https://detectron2.readthedocs.io/en/latest/tutorials/datasets.html"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":296,"status":"ok","timestamp":1650815877530,"user":{"displayName":"Pedro Alarcon Granadeno","userId":"03221847207112830166"},"user_tz":240},"id":"ucKK7C06FdSV","outputId":"0947500c-8cbe-4c19-fce6-35afdf645a13"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[32m[04/24 15:57:57 d2.data.datasets.coco]: \u001b[0mLoaded 44 images in COCO format from /content/gdrive/MyDrive/Amazon Project/clutterized/new_train.json\n"]}],"source":["from detectron2.data.datasets import register_coco_instances\n","from detectron2.structures import BoxMode\n","\n","#telling detectron what to call my training dataset, path to json file, and path to images\n","register_coco_instances(\"my_dataset_train\", {}, annotations_train, image_path)\n","\n","#visualize training data\n","train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n","train_dataset = DatasetCatalog.get(\"my_dataset_train\") #Call the registered function and return its results (return list[dict] – dataset annotations.)"]},{"cell_type":"markdown","metadata":{"id":"KKJ372FmssIX"},"source":["Here we visualize random sample from our dataset, including the bbox, polygon segmentation and it's label"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1XHl56uNIzJ6bWul8E0QTRv1wyLin7caM"},"executionInfo":{"elapsed":22818,"status":"ok","timestamp":1650815900343,"user":{"displayName":"Pedro Alarcon Granadeno","userId":"03221847207112830166"},"user_tz":240},"id":"ZTgAWZusm-N3","outputId":"bb674bed-749c-43f6-fc62-41e7c06349e0"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["import random\n","from detectron2.utils.visualizer import Visualizer\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","rows, cols = 4, 3\n","j = 0\n","fig = plt.figure(figsize=(45,45))\n","\n","for d in random.sample(train_dataset, 11): #returns 11 random samples from the training dataset\n","    img = cv2.imread(d[\"file_name\"]) #respective file name\n","    visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.2)\n","    out = visualizer.draw_dataset_dict(d)\n","    fig.add_subplot(rows, cols, j+1)\n","    j = j+ 1\n","    plt.imshow(out.get_image()[:, :, ::-1])\n","\n","\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"0H886Z3Dx0zI"},"source":["# Fine Tunning and Training"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":558065,"status":"ok","timestamp":1650816458405,"user":{"displayName":"Pedro Alarcon Granadeno","userId":"03221847207112830166"},"user_tz":240},"id":"pGV410b0x5AG","outputId":"d3005d4a-f258-496d-bdbe-51697035ea8c"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[32m[04/24 15:58:29 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=11, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)\n","    )\n","    (mask_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (mask_head): MaskRCNNConvUpsampleHead(\n","      (mask_fcn1): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn2): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn3): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (mask_fcn4): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n","      (deconv_relu): ReLU()\n","      (predictor): Conv2d(256, 10, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","  )\n",")\n","\u001b[32m[04/24 15:58:29 d2.data.datasets.coco]: \u001b[0mLoaded 44 images in COCO format from /content/gdrive/MyDrive/Amazon Project/clutterized/new_train.json\n","\u001b[32m[04/24 15:58:29 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 44 images left.\n","\u001b[32m[04/24 15:58:29 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n","\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n","|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n","|    ball    | 26           | calculator | 43           | controller | 43           |\n","|    cup     | 38           | hair brush | 41           | hard drive | 29           |\n","|  head set  | 46           |  keyboard  | 50           |   mouse    | 41           |\n","|   tongs    | 35           |            |              |            |              |\n","|   total    | 392          |            |              |            |              |\u001b[0m\n","\u001b[32m[04/24 15:58:29 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[04/24 15:58:29 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[04/24 15:58:29 d2.data.common]: \u001b[0mSerializing 44 elements to byte tensors and concatenating them all ...\n","\u001b[32m[04/24 15:58:29 d2.data.common]: \u001b[0mSerialized dataset takes 2.99 MiB\n"]},{"name":"stderr","output_type":"stream","text":["model_final_f10217.pkl: 178MB [00:04, 39.0MB/s]                           \n","Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (10, 256, 1, 1) in the model! You might want to double check if this is expected.\n","Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (10,) in the model! You might want to double check if this is expected.\n","Some model parameters or buffers are not found in the checkpoint:\n","\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n","\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[32m[04/24 15:58:39 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/detectron2/structures/image_list.py:88: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  max_size = (max_size + (stride - 1)) // stride * stride\n","/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[32m[04/24 15:59:01 d2.utils.events]: \u001b[0m eta: 0:10:31  iter: 19  total_loss: 4.331  loss_cls: 2.549  loss_box_reg: 0.9227  loss_mask: 0.6927  loss_rpn_cls: 0.1782  loss_rpn_loc: 0.05393  time: 1.0924  data_time: 0.5459  lr: 8.1588e-06  max_mem: 2549M\n","\u001b[32m[04/24 15:59:20 d2.utils.events]: \u001b[0m eta: 0:09:15  iter: 39  total_loss: 4.085  loss_cls: 2.333  loss_box_reg: 0.9114  loss_mask: 0.6892  loss_rpn_cls: 0.121  loss_rpn_loc: 0.04516  time: 1.0082  data_time: 0.3655  lr: 1.6484e-05  max_mem: 2549M\n","\u001b[32m[04/24 15:59:38 d2.utils.events]: \u001b[0m eta: 0:08:42  iter: 59  total_loss: 3.746  loss_cls: 1.903  loss_box_reg: 0.9199  loss_mask: 0.6836  loss_rpn_cls: 0.1045  loss_rpn_loc: 0.04829  time: 0.9688  data_time: 0.3371  lr: 2.4809e-05  max_mem: 2549M\n","\u001b[32m[04/24 15:59:56 d2.utils.events]: \u001b[0m eta: 0:08:10  iter: 79  total_loss: 3.102  loss_cls: 1.404  loss_box_reg: 0.9273  loss_mask: 0.6739  loss_rpn_cls: 0.0694  loss_rpn_loc: 0.04122  time: 0.9475  data_time: 0.3284  lr: 3.3134e-05  max_mem: 2549M\n","\u001b[32m[04/24 16:00:14 d2.utils.events]: \u001b[0m eta: 0:07:48  iter: 99  total_loss: 2.793  loss_cls: 1.072  loss_box_reg: 0.9228  loss_mask: 0.6563  loss_rpn_cls: 0.03796  loss_rpn_loc: 0.04291  time: 0.9373  data_time: 0.3325  lr: 4.1459e-05  max_mem: 2549M\n","\u001b[32m[04/24 16:00:31 d2.utils.events]: \u001b[0m eta: 0:07:25  iter: 119  total_loss: 2.73  loss_cls: 0.9843  loss_box_reg: 0.9369  loss_mask: 0.6406  loss_rpn_cls: 0.08222  loss_rpn_loc: 0.05008  time: 0.9275  data_time: 0.3218  lr: 4.9784e-05  max_mem: 2549M\n","\u001b[32m[04/24 16:00:49 d2.utils.events]: \u001b[0m eta: 0:07:04  iter: 139  total_loss: 2.574  loss_cls: 0.9561  loss_box_reg: 0.94  loss_mask: 0.6182  loss_rpn_cls: 0.02298  loss_rpn_loc: 0.04505  time: 0.9228  data_time: 0.3309  lr: 5.8109e-05  max_mem: 2549M\n","\u001b[32m[04/24 16:01:07 d2.utils.events]: \u001b[0m eta: 0:06:42  iter: 159  total_loss: 2.511  loss_cls: 0.9129  loss_box_reg: 0.9424  loss_mask: 0.5909  loss_rpn_cls: 0.01956  loss_rpn_loc: 0.03853  time: 0.9174  data_time: 0.3188  lr: 6.6434e-05  max_mem: 2549M\n","\u001b[32m[04/24 16:01:25 d2.utils.events]: \u001b[0m eta: 0:06:20  iter: 179  total_loss: 2.491  loss_cls: 0.8972  loss_box_reg: 0.9297  loss_mask: 0.5646  loss_rpn_cls: 0.02218  loss_rpn_loc: 0.04665  time: 0.9135  data_time: 0.2982  lr: 7.4759e-05  max_mem: 2549M\n","\u001b[32m[04/24 16:01:42 d2.utils.events]: \u001b[0m eta: 0:06:00  iter: 199  total_loss: 2.392  loss_cls: 0.8662  loss_box_reg: 0.9333  loss_mask: 0.5273  loss_rpn_cls: 0.02129  loss_rpn_loc: 0.04748  time: 0.9110  data_time: 0.3284  lr: 8.3084e-05  max_mem: 2549M\n","\u001b[32m[04/24 16:02:00 d2.utils.events]: \u001b[0m eta: 0:05:40  iter: 219  total_loss: 2.327  loss_cls: 0.8342  loss_box_reg: 0.9248  loss_mask: 0.4972  loss_rpn_cls: 0.01584  loss_rpn_loc: 0.04348  time: 0.9074  data_time: 0.3031  lr: 9.1409e-05  max_mem: 2549M\n","\u001b[32m[04/24 16:02:17 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 239  total_loss: 2.274  loss_cls: 0.8155  loss_box_reg: 0.9123  loss_mask: 0.47  loss_rpn_cls: 0.0169  loss_rpn_loc: 0.04992  time: 0.9049  data_time: 0.2962  lr: 9.9734e-05  max_mem: 2549M\n","\u001b[32m[04/24 16:02:35 d2.utils.events]: \u001b[0m eta: 0:05:04  iter: 259  total_loss: 2.161  loss_cls: 0.7805  loss_box_reg: 0.9027  loss_mask: 0.4316  loss_rpn_cls: 0.0134  loss_rpn_loc: 0.03518  time: 0.9041  data_time: 0.3199  lr: 0.00010806  max_mem: 2549M\n","\u001b[32m[04/24 16:02:53 d2.utils.events]: \u001b[0m eta: 0:04:46  iter: 279  total_loss: 2.137  loss_cls: 0.759  loss_box_reg: 0.8789  loss_mask: 0.4046  loss_rpn_cls: 0.01649  loss_rpn_loc: 0.04464  time: 0.9030  data_time: 0.3081  lr: 0.00011638  max_mem: 2549M\n","\u001b[32m[04/24 16:03:11 d2.utils.events]: \u001b[0m eta: 0:04:29  iter: 299  total_loss: 2.069  loss_cls: 0.7347  loss_box_reg: 0.8779  loss_mask: 0.3932  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.04338  time: 0.9022  data_time: 0.3282  lr: 0.00012471  max_mem: 2549M\n","\u001b[32m[04/24 16:03:29 d2.utils.events]: \u001b[0m eta: 0:04:10  iter: 319  total_loss: 1.972  loss_cls: 0.6908  loss_box_reg: 0.869  loss_mask: 0.3523  loss_rpn_cls: 0.007592  loss_rpn_loc: 0.03273  time: 0.9022  data_time: 0.3272  lr: 0.00013303  max_mem: 2549M\n","\u001b[32m[04/24 16:03:47 d2.utils.events]: \u001b[0m eta: 0:03:53  iter: 339  total_loss: 1.869  loss_cls: 0.6506  loss_box_reg: 0.8385  loss_mask: 0.3205  loss_rpn_cls: 0.01184  loss_rpn_loc: 0.03974  time: 0.9016  data_time: 0.3000  lr: 0.00014136  max_mem: 2549M\n","\u001b[32m[04/24 16:04:05 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 359  total_loss: 1.803  loss_cls: 0.626  loss_box_reg: 0.8169  loss_mask: 0.2917  loss_rpn_cls: 0.01465  loss_rpn_loc: 0.03623  time: 0.9007  data_time: 0.3028  lr: 0.00014968  max_mem: 2549M\n","\u001b[32m[04/24 16:04:23 d2.utils.events]: \u001b[0m eta: 0:03:16  iter: 379  total_loss: 1.67  loss_cls: 0.5509  loss_box_reg: 0.7717  loss_mask: 0.2774  loss_rpn_cls: 0.01086  loss_rpn_loc: 0.04062  time: 0.9002  data_time: 0.3069  lr: 0.00015801  max_mem: 2549M\n","\u001b[32m[04/24 16:04:40 d2.utils.events]: \u001b[0m eta: 0:02:58  iter: 399  total_loss: 1.485  loss_cls: 0.5029  loss_box_reg: 0.7032  loss_mask: 0.2373  loss_rpn_cls: 0.01232  loss_rpn_loc: 0.03422  time: 0.9000  data_time: 0.3163  lr: 0.00016633  max_mem: 2549M\n","\u001b[32m[04/24 16:04:58 d2.utils.events]: \u001b[0m eta: 0:02:40  iter: 419  total_loss: 1.399  loss_cls: 0.4644  loss_box_reg: 0.6432  loss_mask: 0.229  loss_rpn_cls: 0.006946  loss_rpn_loc: 0.04831  time: 0.8989  data_time: 0.3026  lr: 0.00017466  max_mem: 2549M\n","\u001b[32m[04/24 16:05:15 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 439  total_loss: 1.222  loss_cls: 0.3946  loss_box_reg: 0.5513  loss_mask: 0.2265  loss_rpn_cls: 0.004913  loss_rpn_loc: 0.03785  time: 0.8973  data_time: 0.3056  lr: 0.00018298  max_mem: 2549M\n","\u001b[32m[04/24 16:05:33 d2.utils.events]: \u001b[0m eta: 0:02:04  iter: 459  total_loss: 1.098  loss_cls: 0.3657  loss_box_reg: 0.477  loss_mask: 0.2051  loss_rpn_cls: 0.00736  loss_rpn_loc: 0.04487  time: 0.8959  data_time: 0.3000  lr: 0.00019131  max_mem: 2549M\n","\u001b[32m[04/24 16:05:50 d2.utils.events]: \u001b[0m eta: 0:01:46  iter: 479  total_loss: 1.067  loss_cls: 0.363  loss_box_reg: 0.4549  loss_mask: 0.2125  loss_rpn_cls: 0.004471  loss_rpn_loc: 0.04253  time: 0.8952  data_time: 0.3099  lr: 0.00019963  max_mem: 2549M\n","\u001b[32m[04/24 16:06:08 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 499  total_loss: 0.9235  loss_cls: 0.3044  loss_box_reg: 0.3836  loss_mask: 0.1917  loss_rpn_cls: 0.003291  loss_rpn_loc: 0.03343  time: 0.8940  data_time: 0.2846  lr: 0.00020796  max_mem: 2549M\n","\u001b[32m[04/24 16:06:25 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 519  total_loss: 0.8794  loss_cls: 0.2957  loss_box_reg: 0.3684  loss_mask: 0.1837  loss_rpn_cls: 0.006018  loss_rpn_loc: 0.04379  time: 0.8933  data_time: 0.3159  lr: 0.00021628  max_mem: 2549M\n","\u001b[32m[04/24 16:06:43 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 539  total_loss: 0.8941  loss_cls: 0.2747  loss_box_reg: 0.3733  loss_mask: 0.1874  loss_rpn_cls: 0.003623  loss_rpn_loc: 0.03563  time: 0.8927  data_time: 0.3123  lr: 0.00022461  max_mem: 2549M\n","\u001b[32m[04/24 16:07:00 d2.utils.events]: \u001b[0m eta: 0:00:35  iter: 559  total_loss: 0.8498  loss_cls: 0.2725  loss_box_reg: 0.3407  loss_mask: 0.1647  loss_rpn_cls: 0.005101  loss_rpn_loc: 0.04319  time: 0.8924  data_time: 0.3170  lr: 0.00023293  max_mem: 2549M\n","\u001b[32m[04/24 16:07:18 d2.utils.events]: \u001b[0m eta: 0:00:17  iter: 579  total_loss: 0.7781  loss_cls: 0.231  loss_box_reg: 0.3311  loss_mask: 0.1745  loss_rpn_cls: 0.004668  loss_rpn_loc: 0.03881  time: 0.8912  data_time: 0.3104  lr: 0.00024126  max_mem: 2549M\n","\u001b[32m[04/24 16:07:38 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 599  total_loss: 0.7412  loss_cls: 0.2268  loss_box_reg: 0.2973  loss_mask: 0.1642  loss_rpn_cls: 0.002852  loss_rpn_loc: 0.03539  time: 0.8913  data_time: 0.3199  lr: 0.00024958  max_mem: 2549M\n","\u001b[32m[04/24 16:07:38 d2.engine.hooks]: \u001b[0mOverall training speed: 598 iterations in 0:08:53 (0.8913 s / it)\n","\u001b[32m[04/24 16:07:38 d2.engine.hooks]: \u001b[0mTotal training time: 0:08:56 (0:00:03 on hooks)\n"]}],"source":["from detectron2.engine import DefaultTrainer\n","\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n","cfg.DATASETS.TEST = ()\n","cfg.DATALOADER.NUM_WORKERS = 2\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n","cfg.SOLVER.IMS_PER_BATCH = 2\n","cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n","cfg.SOLVER.MAX_ITER = 600  # 600 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset\n","cfg.SOLVER.STEPS = []        # do not decay learning rate\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 200  # faster, and good enough for this toy dataset (default: 512)\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n","# NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.\n","cfg.OUTPUT_DIR = '/content/gdrive/MyDrive/Amazon Project/clutterized/output/'\n","os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n","#trainer = CustomTrainer(cfg)\n","trainer = DefaultTrainer(cfg) \n","trainer.resume_or_load(resume=False)\n","trainer.train()"]},{"cell_type":"markdown","metadata":{"id":"kloa0LYsqDuQ"},"source":["# Training Curves"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1650816458407,"user":{"displayName":"Pedro Alarcon Granadeno","userId":"03221847207112830166"},"user_tz":240},"id":"8SXQt10P7apP"},"outputs":[],"source":["# Look at training curves in tensorboard:\n","#%load_ext tensorboard\n","#%tensorboard --logdir output"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Detectron.ipynb","provenance":[]},"interpreter":{"hash":"92829e2fac57cbff12d0f5f666c000e50d10f2158a7e425f09180d35edebd327"},"kernelspec":{"display_name":"Python 3.8.8 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":0}
