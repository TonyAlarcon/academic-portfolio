---
---

@inproceedings{holdgraf_evidence_2014,
	address = {Brisbane, Australia, Australia},
	title = {Evidence for {Predictive} {Coding} in {Human} {Auditory} {Cortex}},
	booktitle = {International {Conference} on {Cognitive} {Neuroscience}},
	publisher = {Frontiers in Neuroscience},
	author = {Holdgraf, Christopher Ramsay and de Heer, Wendy and Pasley, Brian N. and Knight, Robert T.},
	year = {2014}
}

@article{holdgraf_rapid_2016,
	title = {Rapid tuning shifts in human auditory cortex enhance speech intelligibility},
	volume = {7},
	issn = {2041-1723},
	url = {http://www.nature.com/doifinder/10.1038/ncomms13654},
	doi = {10.1038/ncomms13654},
	number = {May},
	journal = {Nature Communications},
	author = {Holdgraf, Christopher Ramsay and de Heer, Wendy and Pasley, Brian N. and Rieger, Jochem W. and Crone, Nathan and Lin, Jack J. and Knight, Robert T. and Theunissen, Frédéric E.},
	year = {2016},
	pages = {13654},
	file = {Holdgraf et al. - 2016 - Rapid tuning shifts in human auditory cortex enhance speech intelligibility.pdf:C\:\\Users\\chold\\Zotero\\storage\\MDQP3JWE\\Holdgraf et al. - 2016 - Rapid tuning shifts in human auditory cortex enhance speech intelligibility.pdf:application/pdf}
}

@inproceedings{holdgraf_portable_2017,
	title = {Portable learning environments for hands-on computational instruction using container-and cloud-based technology to teach data science},
	volume = {Part F1287},
	isbn = {978-1-4503-5272-7},
	doi = {10.1145/3093338.3093370},
	abstract = {© 2017 ACM. There is an increasing interest in learning outside of the traditional classroom setting. This is especially true for topics covering computational tools and data science, as both are challenging to incorporate in the standard curriculum. These atypical learning environments offer new opportunities for teaching, particularly when it comes to combining conceptual knowledge with hands-on experience/expertise with methods and skills. Advances in cloud computing and containerized environments provide an attractive opportunity to improve the effciency and ease with which students can learn. This manuscript details recent advances towards using commonly-Available cloud computing services and advanced cyberinfrastructure support for improving the learning experience in bootcamp-style events. We cover the benets (and challenges) of using a server hosted remotely instead of relying on student laptops, discuss the technology that was used in order to make this possible, and give suggestions for how others could implement and improve upon this model for pedagogy and reproducibility.},
	booktitle = {{ACM} {International} {Conference} {Proceeding} {Series}},
	author = {Holdgraf, Christopher Ramsay and Culich, A. and Rokem, A. and Deniz, F. and Alegro, M. and Ushizima, D.},
	year = {2017},
	keywords = {Teaching, Bootcamps, Cloud computing, Data science, Docker, Pedagogy}
}

@article{holdgraf_encoding_2017,
	title = {Encoding and decoding models in cognitive electrophysiology},
	volume = {11},
	issn = {16625137},
	doi = {10.3389/fnsys.2017.00061},
	abstract = {© 2017 Holdgraf, Rieger, Micheli, Martin, Knight and Theunissen. Cognitive neuroscience has seen rapid growth in the size and complexity of data recorded from the human brain as well as in the computational tools available to analyze this data. This data explosion has resulted in an increased use of multivariate, model-based methods for asking neuroscience questions, allowing scientists to investigate multiple hypotheses with a single dataset, to use complex, time-varying stimuli, and to study the human brain under more naturalistic conditions. These tools come in the form of “Encoding” models, in which stimulus features are used to model brain activity, and “Decoding” models, in which neural features are used to generated a stimulus output. Here we review the current state of encoding and decoding models in cognitive electrophysiology and provide a practical guide toward conducting experiments and analyses in this emerging field. Our examples focus on using linear models in the study of human language and audition. We show how to calculate auditory receptive fields from natural sounds as well as how to decode neural recordings to predict speech. The paper aims to be a useful tutorial to these approaches, and a practical introduction to using machine learning and applied statistics to build models of neural activity. The data analytic approaches we discuss may also be applied to other sensory modalities, motor systems, and cognitive systems, and we cover some examples in these areas. In addition, a collection of Jupyter notebooks is publicly available as a complement to the material covered in this paper, providing code examples and tutorials for predictive modeling in python. The aimis to provide a practical understanding of predictivemodeling of human brain data and to propose best-practices in conducting these analyses.},
	journal = {Frontiers in Systems Neuroscience},
	author = {Holdgraf, Christopher Ramsay and Rieger, J.W. and Micheli, C. and Martin, S. and Knight, R.T. and Theunissen, F.E.},
	year = {2017},
	keywords = {Decoding models, Encoding models, Electrocorticography (ECoG), Electrophysiology/evoked potentials, Machine learning applied to neuroscience, Natural stimuli, Predictive modeling, Tutorials}
}

@book{ruby,
  title     = {The Ruby Programming Language},
  author    = {Flanagan, David and Matsumoto, Yukihiro},
  year      = {2008},
  publisher = {O'Reilly Media}
}

 @inproceedings{10.1109/ICSE.2019.00086, author = {Zhang, Jian and Wang, Xu and Zhang, Hongyu and Sun, Hailong and Wang, Kaixuan and Liu, Xudong}, title = {A Novel Neural Source Code Representation Based on Abstract Syntax Tree}, year = {2019}, publisher = {IEEE Press}, url = {https://doi.org/10.1109/ICSE.2019.00086}, doi = {10.1109/ICSE.2019.00086}, abstract = {Exploiting machine learning techniques for analyzing programs has attracted much attention. One key problem is how to represent code fragments well for follow-up analysis. Traditional information retrieval based methods often treat programs as natural language texts, which could miss important semantic information of source code. Recently, state-of-the-art studies demonstrate that abstract syntax tree (AST) based neural models can better represent source code. However, the sizes of ASTs are usually large and the existing models are prone to the long-term dependency problem. In this paper, we propose a novel AST-based Neural Network (ASTNN) for source code representation. Unlike existing models that work on entire ASTs, ASTNN splits each large AST into a sequence of small statement trees, and encodes the statement trees to vectors by capturing the lexical and syntactical knowledge of statements. Based on the sequence of statement vectors, a bidirectional RNN model is used to leverage the naturalness of statements and finally produce the vector representation of a code fragment. We have applied our neural network based source code representation method to two common program comprehension tasks: source code classification and code clone detection. Experimental results on the two tasks indicate that our model is superior to state-of-the-art approaches.}, booktitle = {Proceedings of the 41st International Conference on Software Engineering}, pages = {783–794}, numpages = {12}, keywords = {code classification, source code representation, abstract syntax tree, neural network, code clone detection}, location = {Montreal, Quebec, Canada}, series = {ICSE '19} }
 
 @article{DBLP:journals/corr/abs-1909-03496,
  author    = {Yaqin Zhou and
               Shangqing Liu and
               Jing Kai Siow and
               Xiaoning Du and
               Yang Liu},
  title     = {Devign: Effective Vulnerability Identification by Learning Comprehensive
               Program Semantics via Graph Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1909.03496},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.03496},
  eprinttype = {arXiv},
  eprint    = {1909.03496},
  timestamp = {Fri, 11 Feb 2022 09:12:45 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-03496.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@ARTICLE{9167194,
  author={Bilgin, Zeki and Ersoy, Mehmet Akif and Soykan, Elif Ustundag and Tomur, Emrah and Çomak, Pinar and Karaçay, Leyli},
  journal={IEEE Access}, 
  title={Vulnerability Prediction From Source Code Using Machine Learning}, 
  year={2020},
  volume={8},
  number={},
  pages={150672-150684},
  doi={10.1109/ACCESS.2020.3016774}}

@article{DBLP:journals/corr/abs-1807-04320,
  author    = {Rebecca L. Russell and
               Louis Y. Kim and
               Lei H. Hamilton and
               Tomo Lazovich and
               Jacob A. Harer and
               Onur Ozdemir and
               Paul M. Ellingwood and
               Marc W. McConley},
  title     = {Automated Vulnerability Detection in Source Code Using Deep Representation
               Learning},
  journal   = {CoRR},
  volume    = {abs/1807.04320},
  year      = {2018},
  url       = {http://arxiv.org/abs/1807.04320},
  eprinttype = {arXiv},
  eprint    = {1807.04320},
  timestamp = {Mon, 13 Aug 2018 16:46:23 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1807-04320.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Hornik1989MultilayerFN,
  title={Multilayer feedforward networks are universal approximators},
  author={Kurt Hornik and Maxwell B. Stinchcombe and Halbert L. White},
  journal={Neural Networks},
  year={1989},
  volume={2},
  pages={359-366}
}

@article{https://doi.org/10.48550/arxiv.2110.05861,
  doi = {10.48550/ARXIV.2110.05861},
  
  url = {https://arxiv.org/abs/2110.05861},
  
  author = {Biscione, Valerio and Bowers, Jeffrey S.},
  
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Convolutional Neural Networks Are Not Invariant to Translation, but They Can Learn to Be},
  
  publisher = {arXiv},
  
  year = {2021},
  
  }
  
  @inproceedings{Delaitre2018SATEVR,
  title = {SATE V report: ten years of static analysis tool expositions},
  author = {Aur{\'e}lien Delaitre and Bertrand Stivalet and Paul E. Black and Vadim Okun and Athos Ribeiro and Terry S. Cohen},
  year = {2018}
}


@inproceedings{10.1109/MSR.2019.00015, author = {Efstathiou, Vasiliki and Spinellis, Diomidis}, title = {Semantic Source Code Models Using Identifier Embeddings}, year = {2019}, publisher = {IEEE Press}, url = {https://doi.org/10.1109/MSR.2019.00015}, doi = {10.1109/MSR.2019.00015}, abstract = {The emergence of online open source repositories in the recent years has led to an explosion in the volume of openly available source code, coupled with metadata that relate to a variety of software development activities. As an effect, in line with recent advances in machine learning research, software maintenance activities are switching from symbolic formal methods to data-driven methods. In this context, the rich semantics hidden in source code identifiers provide opportunities for building semantic representations of code which can assist tasks of code search and reuse. To this end, we deliver in the form of pretrained vector space models, distributed code representations for six popular programming languages, namely, Java, Python, PHP, C, C++, and C#. The models are produced using fastText, a state-of-the-art library for learning word representations. Each model is trained on data from a single programming language; the code mined for producing all models amounts to over 13.000 repositories. We indicate dissimilarities between natural language and source code, as well as variations in coding conventions in between the different programming languages we processed. We describe how these heterogeneities guided the data preprocessing decisions we took and the selection of the training parameters in the released models. Finally, we propose potential applications of the models and discuss limitations of the models.}, booktitle = {Proceedings of the 16th International Conference on Mining Software Repositories}, pages = {29–33}, numpages = {5}, keywords = {fastText, code semantics, vector space models, semantic similarity}, location = {Montreal, Quebec, Canada}, series = {MSR '19} }


 @inproceedings{10.1109/ICSE.2019.00086, author = {Zhang, Jian and Wang, Xu and Zhang, Hongyu and Sun, Hailong and Wang, Kaixuan and Liu, Xudong}, title = {A Novel Neural Source Code Representation Based on Abstract Syntax Tree}, year = {2019}, publisher = {IEEE Press}, url = {https://doi.org/10.1109/ICSE.2019.00086}, doi = {10.1109/ICSE.2019.00086}, abstract = {Exploiting machine learning techniques for analyzing programs has attracted much attention. One key problem is how to represent code fragments well for follow-up analysis. Traditional information retrieval based methods often treat programs as natural language texts, which could miss important semantic information of source code. Recently, state-of-the-art studies demonstrate that abstract syntax tree (AST) based neural models can better represent source code. However, the sizes of ASTs are usually large and the existing models are prone to the long-term dependency problem. In this paper, we propose a novel AST-based Neural Network (ASTNN) for source code representation. Unlike existing models that work on entire ASTs, ASTNN splits each large AST into a sequence of small statement trees, and encodes the statement trees to vectors by capturing the lexical and syntactical knowledge of statements. Based on the sequence of statement vectors, a bidirectional RNN model is used to leverage the naturalness of statements and finally produce the vector representation of a code fragment. We have applied our neural network based source code representation method to two common program comprehension tasks: source code classification and code clone detection. Experimental results on the two tasks indicate that our model is superior to state-of-the-art approaches.}, booktitle = {Proceedings of the 41st International Conference on Software Engineering}, pages = {783–794}, numpages = {12}, keywords = {code classification, source code representation, abstract syntax tree, neural network, code clone detection}, location = {Montreal, Quebec, Canada}, series = {ICSE '19} }



@article{redmon2018yolov3,
  title={Yolov3: An incremental improvement},
  author={Redmon, Joseph and Farhadi, Ali},
  journal={arXiv preprint arXiv:1804.02767},
  year={2018}
}

@inproceedings{he2017mask,
  title={Mask r-cnn},
  author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2961--2969},
  year={2017}
}

@article{russell2008labelme,
  title={LabelMe: a database and web-based tool for image annotation},
  author={Russell, Bryan C and Torralba, Antonio and Murphy, Kevin P and Freeman, William T},
  journal={International journal of computer vision},
  volume={77},
  number={1-3},
  pages={157--173},
  year={2008},
  publisher={Springer}
}

@inproceedings{lin2014microsoft,
  title={Microsoft coco: Common objects in context},
  author={Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and Hays, James and Perona, Pietro and Ramanan, Deva and Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  booktitle={European conference on computer vision},
  pages={740--755},
  year={2014},
  organization={Springer}
}

@misc{NathanRVance2020,
  author = {NathanRVance},
  title = {cv2},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/NathanRVance/cv2}},
}

@misc{hossain2018comprehensive,
      title={A Comprehensive Survey of Deep Learning for Image Captioning}, 
      author={Md. Zakir Hossain and Ferdous Sohel and Mohd Fairuz Shiratuddin and Hamid Laga},
      year={2018},
      eprint={1810.04020},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}}

@inproceedings{wit, 
author = {Srinivasan, Krishna and Raman, Karthik and Chen, Jiecao and Bendersky, Michael and Najork, Marc}, 
title = {WIT: Wikipedia-Based Image Text Dataset for Multimodal Multilingual Machine Learning}, year = {2021}, 
isbn = {9781450380379}, publisher = {Association for Computing Machinery}, 
address = {New York, NY, USA}, url = {https://doi.org/10.1145/3404835.3463257}, 
doi = {10.1145/3404835.3463257}, 
booktitle = {Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2443–2449}, numpages = {7}, 
keywords = {wikipedia, machine learning, image-text retrieval, neural networks, multilingual, dataset, multimodal}, 
location = {Virtual Event, Canada}, series = {SIGIR '21} }




@inproceedings{Papineni2002BleuAM,
  title={Bleu: a Method for Automatic Evaluation of Machine Translation},
  author={Kishore Papineni and Salim Roukos and Todd Ward and Wei-Jing Zhu},
  booktitle={ACL},
  year={2002}
}

@inproceedings{denkowski-lavie-2014-meteor,
    title = "Meteor Universal: Language Specific Translation Evaluation for Any Target Language",
    author = "Denkowski, Michael  and
      Lavie, Alon",
    booktitle = "Proceedings of the Ninth Workshop on Statistical Machine Translation",
    month = jun,
    year = "2014",
    address = "Baltimore, Maryland, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W14-3348",
    doi = "10.3115/v1/W14-3348",
    pages = "376--380",
}

@inproceedings{lin-2004-rouge,
    title = "{ROUGE}: A Package for Automatic Evaluation of Summaries",
    author = "Lin, Chin-Yew",
    booktitle = "Text Summarization Branches Out",
    month = jul,
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-1013",
    pages = "74--81",
}

@inproceedings{7299087,
  author={Vedantam, Ramakrishna and Zitnick, C. Lawrence and Parikh, Devi},
  booktitle={2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={CIDEr: Consensus-based image description evaluation}, 
  year={2015},
  volume={},
  number={},
  pages={4566-4575},
  doi={10.1109/CVPR.2015.7299087}}

@misc{vinyals2015tell,
      title={Show and Tell: A Neural Image Caption Generator}, 
      author={Oriol Vinyals and Alexander Toshev and Samy Bengio and Dumitru Erhan},
      year={2015},
      eprint={1411.4555},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{kiros2014unifying,
      title={Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models}, 
      author={Ryan Kiros and Ruslan Salakhutdinov and Richard S. Zemel},
      year={2014},
      eprint={1411.2539},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{donahue2016longterm,
      title={Long-term Recurrent Convolutional Networks for Visual Recognition and Description}, 
      author={Jeff Donahue and Lisa Anne Hendricks and Marcus Rohrbach and Subhashini Venugopalan and Sergio Guadarrama and Kate Saenko and Trevor Darrell},
      year={2016},
      eprint={1411.4389},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{karpathy2015deep,
      title={Deep Visual-Semantic Alignments for Generating Image Descriptions}, 
      author={Andrej Karpathy and Li Fei-Fei},
      year={2015},
      eprint={1412.2306},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@misc{mao2015learning,
      title={Learning like a Child: Fast Novel Visual Concept Learning from Sentence Descriptions of Images}, 
      author={Junhua Mao and Wei Xu and Yi Yang and Jiang Wang and Zhiheng Huang and Alan Yuille},
      year={2015},
      eprint={1504.06692},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{devlin-etal-2015-language,
    title = "Language Models for Image Captioning: The Quirks and What Works",
    author = "Devlin, Jacob  and
      Cheng, Hao  and
      Fang, Hao  and
      Gupta, Saurabh  and
      Deng, Li  and
      He, Xiaodong  and
      Zweig, Geoffrey  and
      Mitchell, Margaret",
    booktitle = "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    month = jul,
    year = "2015",
    address = "Beijing, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P15-2017",
    doi = "10.3115/v1/P15-2017",
    pages = "100--105",
}

@misc{wu2016value,
      title={What value do explicit high level concepts have in vision to language problems?}, 
      author={Qi Wu and Chunhua Shen and Lingqiao Liu and Anthony Dick and Anton van den Hengel},
      year={2016},
      eprint={1506.01144},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}


@misc{cui2018learning,
      title={Learning to Evaluate Image Captioning}, 
      author={Yin Cui and Guandao Yang and Andreas Veit and Xun Huang and Serge Belongie},
      year={2018},
      eprint={1806.06422},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}